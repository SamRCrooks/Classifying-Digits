{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['label' 'pixel0' 'pixel1' ..., 'pixel781' 'pixel782' 'pixel783']\n",
      " ['1' '0' '0' ..., '0' '0' '0']\n",
      " ['0' '0' '0' ..., '0' '0' '0']\n",
      " ..., \n",
      " ['7' '0' '0' ..., '0' '0' '0']\n",
      " ['6' '0' '0' ..., '0' '0' '0']\n",
      " ['9' '0' '0' ..., '0' '0' '0']]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#This section loads the csv file into a numpy data matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "data = [] # Create empty data matrix\n",
    "\n",
    "#Load csv file into data --- \n",
    "with open('digitData.csv') as csvfile: \n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        if len(row) != 0:\n",
    "            data = data + [row]\n",
    "#---\n",
    "\n",
    "data =  np.asarray(data) #Convert regular array to numpy array.\n",
    "print(data)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  63 171 253 253 170  63\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1  73  73 176 237 253 252 252 252 238\n",
      "  175  21   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  27 120 252 252 252 252 237 215 221 252 253\n",
      "  252  71   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 181 252 252 252 252 252  62   0  16 190 253\n",
      "  252  71   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 119 252 205 103   0   0   0   0  16 191 253\n",
      "  252  71   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   5  35  20   0   0   0   0   0  37 252 253\n",
      "  189  10   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  11 150 252 253\n",
      "   76   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 252 252 191\n",
      "   15   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  47 233 253 253  84\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 109 252 241  97   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  21 212 252 195   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 144 253 252  71   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  32 212 253 255  35   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 115 252 252 159   5   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1  99 242 252 231  41   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1 252 252 252 108   0   0   0   0   0\n",
      "   42 125   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  16 191 253 253 232 109 171 253 253 253 255\n",
      "  253 253 253 255 180   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 161 252 252 252 252 252 253 252 252 252 253\n",
      "  252 252 252 180 128   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 155 236 252 252 252 252 237 215 195  71  72\n",
      "   71  71  71   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  62 252 210 128 252  62   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAUAiEAAkAgFA+j9mnyEboLXm4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107c71518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'for x in range(28):\\n    for y in range(28):\\n        sys.stdout.write(displayPixelValues[x,y].astype(np.str) + \",\")\\n    print()'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell used to visualize data as a human does\n",
    "displayPixelValues = data[23][1:]  #Gather all pixel values from first data point\n",
    "\n",
    "displayPixelValues = np.reshape(displayPixelValues, (-1, 28)) #Reshape data to 28 by 28 array instead of 784 by 1 array\n",
    "displayPixelValues = displayPixelValues.astype(np.int) #Convert the data into integers from strings\n",
    "print(displayPixelValues) #Print out array of single digit\n",
    "\n",
    "plt.matshow(displayPixelValues, fignum=10,cmap=plt.cm.gray) #Make grayscale representation of digit\n",
    "plt.show() #Show grayscale representation of digit\n",
    "\n",
    "\"\"\"for x in range(28):\n",
    "    for y in range(28):\n",
    "        sys.stdout.write(displayPixelValues[x,y].astype(np.str) + \",\")\n",
    "    print()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    #If overflow error, return small values for zero\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "layer0_neurons = 784 #Number of pixels = 784\n",
    "layer1_neurons = 30 #Number of middle layer neurons. I picked 30 for now\n",
    "layer2_neurons = 10 #Output neurons here. \n",
    "                    #The activation of the output neurons are the \"guesses\"\n",
    "#Initialize random weights and biases\n",
    "\n",
    "layer1_b = np.zeros((layer1_neurons,1))#Initialize layer_1 biases to 0. This is a 784 by 1 matrix\n",
    "layer1_w = (2*np.random.random((layer1_neurons,layer0_neurons)) - 1) /100 #Initialize layer_1 weights to a value between -.01 and .01 This is a 30 by 784 matrix\n",
    "layer2_b = np.zeros((layer2_neurons,1)) #Initialize layer_2 biases to 0. This is a 30 by 1 matrix\n",
    "layer2_w = (2*np.random.random((layer2_neurons,layer1_neurons)) - 1) /100 #Initialize layer_2 weights to to a value between -.01 and .01 This is a 10 by 30 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix Calculation of Forward Propogation\n",
    "#\n",
    "trainingSize = 1000 #Number of training sample\n",
    "Xdata = data[1:trainingSize+1,1:] #Get pixel values of data samples\n",
    "Xdata = Xdata.T #Transpose - Make columns rows and rows columns\n",
    "Xdata = Xdata.astype(np.int) #Convert values from string to integer\n",
    "Xdata = Xdata/255 #Remap grayscale values (normalize)\n",
    "\n",
    "labels = data[1:,0].astype(np.int)  #Get labels of each digit an numpy list\n",
    "\n",
    "Xdata.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation 2:\n",
      "[[ 0.50221147  0.50237385  0.50216941 ...,  0.50217624  0.50202286\n",
      "   0.50215832]\n",
      " [ 0.50887489  0.50890915  0.50881077 ...,  0.5088913   0.50887893\n",
      "   0.50890009]\n",
      " [ 0.49584275  0.49617522  0.49580917 ...,  0.49574381  0.49578623\n",
      "   0.49581402]\n",
      " ..., \n",
      " [ 0.50061857  0.5006645   0.5005805  ...,  0.50042097  0.50046936\n",
      "   0.50047225]\n",
      " [ 0.50225205  0.50234564  0.5021646  ...,  0.50218009  0.50222763\n",
      "   0.50210421]\n",
      " [ 0.49708186  0.49735863  0.49709065 ...,  0.49701233  0.49704943\n",
      "   0.49718249]]\n"
     ]
    }
   ],
   "source": [
    "# FP\n",
    "z_1 = np.dot(layer1_w,Xdata)+layer1_b\n",
    "a_1 = sigmoid(z_1)\n",
    "\n",
    "z_2 = np.dot(layer2_w,a_1)+layer2_b\n",
    "a_2 = sigmoid(z_2)\n",
    "\n",
    "print(\"activation 2:\")\n",
    "print(a_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.99% Accurate\n",
      "[[  1.82113590e-09   9.93171032e-01   3.94543812e-09 ...,   1.65509255e-07\n",
      "    9.57266816e-03   3.84473872e-05]\n",
      " [  9.94227871e-01   2.11329904e-08   9.98859692e-01 ...,   5.67321655e-03\n",
      "    2.46121537e-05   9.30775819e-06]\n",
      " [  8.91421781e-04   1.97624100e-03   7.96294186e-03 ...,   4.95478662e-09\n",
      "    3.04634385e-03   3.17500676e-05]\n",
      " ..., \n",
      " [  1.04472846e-03   3.15520536e-04   3.36791277e-03 ...,   2.19598980e-03\n",
      "    5.79347259e-07   5.01027297e-03]\n",
      " [  4.54223639e-03   4.05653553e-05   5.01585129e-04 ...,   1.49442323e-03\n",
      "    1.26498741e-06   8.81851622e-06]\n",
      " [  5.60552595e-04   2.82465982e-04   1.94811813e-04 ...,   9.93364262e-01\n",
      "    5.12744778e-06   6.14545623e-03]]\n",
      "predictions:  [1, 0, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 1, 3, 3, 1, 2, 0, 7, 5, 8, 6, 2, 0, 2, 3, 6, 9, 9, 7, 8, 9, 4, 9, 2, 1, 3, 1, 1, 4, 9, 1, 4, 4, 2, 6, 3, 7, 7, 4, 7, 5, 1, 9, 0, 2, 2, 3, 9, 1, 1, 1, 5, 0, 6, 3, 4, 8, 1, 0, 3, 9, 6, 2, 6, 4, 7, 1, 4, 1, 5, 4, 8, 9, 2, 9, 9, 8, 9, 6, 3, 6, 4, 6, 2, 9, 1, 2, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Calculation\n",
    "testSize = 100\n",
    "predictions = []\n",
    "for i in range(testSize):\n",
    "    maxIndex = 0\n",
    "    maxValue = a_2[0,i]\n",
    "    for j in range(a_2[:,i].size):\n",
    "        if(a_2[j,i] > maxValue):\n",
    "            maxIndex = j\n",
    "            maxValue = a_2[j,i]\n",
    "    #print(\"highest a_2 value for digit\",i,\": \", maxValue)\n",
    "    \n",
    "    predictions.append(maxIndex)\n",
    "\n",
    "#print(\"predictions: \")\n",
    "#print(predictions)\n",
    "\n",
    "correct = 0\n",
    "total = trainingSize+1 \n",
    "for i in range(testSize):\n",
    "    if(labels[i] == predictions[i]):\n",
    "        correct+=1\n",
    "accuracy = round(((correct/total)*100),2)\n",
    "print(str(accuracy) + '% Accurate')\n",
    "print(a_2)\n",
    "print(\"predictions: \",predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Squared Error Sum Calculation Used in Back Propogation\n",
    "\n",
    "errors = a_2.copy() #Copy elements of activation_2 into errors\n",
    "for d in range(trainingSize):\n",
    "    target = labels[d] #Get label of current digit\n",
    "    errors[target][d] = 1 - a_2[target][d] #Get error of index of target value\n",
    "    squaredErrorSum = 0 \n",
    "    for e in range(errors[:,d].size):\n",
    "        squaredErrorSum += (errors[e][d] ** 2) #Sum up errors and square them\n",
    "   # print(\"Squared error sum for digit \",d,\" is: \",squaredErrorSum)\n",
    "    \n",
    "#print('a2: \\n',a_2)\n",
    "#print(\"errors: \\n\",errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23487619,  0.23486681,  0.23487862, ...,  0.23487823,\n",
       "         0.23488709,  0.23487926],\n",
       "       [ 0.23448912,  0.23448712,  0.23449286, ...,  0.23448816,\n",
       "         0.23448888,  0.23448765],\n",
       "       [ 0.23524216,  0.23522315,  0.23524408, ...,  0.23524781,\n",
       "         0.23524539,  0.2352438 ],\n",
       "       ..., \n",
       "       [ 0.23496809,  0.23496544,  0.23497028, ...,  0.23497947,\n",
       "         0.23497669,  0.23497652],\n",
       "       [ 0.23487385,  0.23486844,  0.2348789 , ...,  0.234878  ,\n",
       "         0.23487526,  0.23488239],\n",
       "       [ 0.23517126,  0.2351554 ,  0.23517076, ...,  0.23517524,\n",
       "         0.23517312,  0.2351655 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def der_sigmoid(x):\n",
    "    return (sigmoid(x)*(1-sigmoid(x)))\n",
    "\n",
    "der_sigmoid(a_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwlCIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107ec56d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graphing accuracy\n",
    "\n",
    "plt.plot(accList) #Put error/accuracy percentages in here\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_cost(y, a):\n",
    "    error = np.multiply(y,np.log(a)) + np.multiply((1-y),np.log((1-a)))\n",
    "    errorSum = np.sum(error)\n",
    "    meanErrorSum = -errorSum/(y.shape[1])\n",
    "    return meanErrorSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.246360709\n"
     ]
    }
   ],
   "source": [
    "target = np.zeros([10,trainingSize])\n",
    "for i in range(trainingSize):\n",
    "    target[labels[i],i] = 1\n",
    "cost = cross_entropy_cost(target,a_2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter Acc:  0.089\n",
      "Iter Acc:  0.124\n",
      "Iter Acc:  0.124\n",
      "Iter Acc:  0.173\n",
      "Iter Acc:  0.367\n",
      "Iter Acc:  0.526\n",
      "Iter Acc:  0.609\n",
      "Iter Acc:  0.654\n",
      "Iter Acc:  0.703\n",
      "Iter Acc:  0.747\n",
      "Iter Acc:  0.79\n",
      "Iter Acc:  0.815\n",
      "Iter Acc:  0.845\n",
      "Iter Acc:  0.857\n",
      "Iter Acc:  0.87\n",
      "Iter Acc:  0.884\n",
      "Iter Acc:  0.891\n",
      "Iter Acc:  0.894\n",
      "Iter Acc:  0.902\n",
      "Iter Acc:  0.905\n",
      "Iter Acc:  0.913\n",
      "Iter Acc:  0.918\n",
      "Iter Acc:  0.924\n",
      "Iter Acc:  0.928\n",
      "Iter Acc:  0.929\n",
      "Iter Acc:  0.934\n",
      "Iter Acc:  0.939\n",
      "Iter Acc:  0.942\n",
      "Iter Acc:  0.943\n",
      "Iter Acc:  0.95\n",
      "Iter Acc:  0.951\n",
      "Iter Acc:  0.953\n",
      "Iter Acc:  0.955\n",
      "Iter Acc:  0.959\n",
      "Iter Acc:  0.96\n",
      "Iter Acc:  0.962\n",
      "Iter Acc:  0.965\n",
      "Iter Acc:  0.965\n",
      "Iter Acc:  0.968\n",
      "Iter Acc:  0.969\n",
      "Iter Acc:  0.971\n",
      "Iter Acc:  0.973\n",
      "Iter Acc:  0.974\n",
      "Iter Acc:  0.976\n",
      "Iter Acc:  0.977\n",
      "Iter Acc:  0.978\n",
      "Iter Acc:  0.98\n",
      "Iter Acc:  0.98\n",
      "Iter Acc:  0.98\n",
      "Iter Acc:  0.981\n"
     ]
    }
   ],
   "source": [
    "#Initialize random weights and biases\n",
    "layer1_b = np.zeros((layer1_neurons,1))#Initialize layer_1 biases to 0. This is a 784 by 1 matrix\n",
    "layer1_w = (2*np.random.random((layer1_neurons,layer0_neurons)) - 1) /100 #Initialize layer_1 weights to a value between -.01 and .01 This is a 30 by 784 matrix\n",
    "layer2_b = np.zeros((layer2_neurons,1)) #Initialize layer_2 biases to 0. This is a 30 by 1 matrix\n",
    "layer2_w = (2*np.random.random((layer2_neurons,layer1_neurons)) - 1) /100 #Initialize layer_2 weights to to a value between -.01 and .01 This is a 10 by 30 matrix\n",
    "\n",
    "accList=[]\n",
    "\n",
    "iterations = 500\n",
    "for i in range(iterations):\n",
    "    # FP\n",
    "    z_1 = np.dot(layer1_w,Xdata)+layer1_b\n",
    "    a_1 = sigmoid(z_1)\n",
    "\n",
    "    z_2 = np.dot(layer2_w,a_1)+layer2_b\n",
    "    a_2 = sigmoid(z_2)\n",
    "\n",
    "\n",
    "    cost = cross_entropy_cost(target,a_2)\n",
    "    if(i % 10 == 0):\n",
    "        #print(cost)\n",
    "        acc = evaluateNetworkAccuracy(Xdata,labels[0:trainingSize],layer1_w,layer1_b,layer2_w,layer2_b)\n",
    "        accList.append(acc)\n",
    "        print('Iter','Acc: ', acc)\n",
    "        \n",
    "    #Back Prop\n",
    "    learningRate = 0.00075\n",
    "    #Change to all with functions #Dimensions\n",
    "    der_a2 = -np.divide(target,a_2) + np.divide(1-target, 1-a_2)\n",
    "    der_z2 = der_a2*a_2*(1-a_2)\n",
    "    der_w2 = np.dot(der_z2,a_1.T)\n",
    "    der_b2 = 0*np.sum(der_z2,axis = 1,keepdims=True)/trainingSize\n",
    "    der_a1 = np.dot(layer2_w.T,der_z2)\n",
    "    der_z1 = der_a1*a_1*(1-a_1)\n",
    "    der_w1 = np.dot(der_z1,Xdata.T)\n",
    "    der_b1 = 0*np.sum(der_z1,axis = 1,keepdims=True)/trainingSize\n",
    "\n",
    "    layer2_w = layer2_w - learningRate*der_w2\n",
    "    layer2_b = layer2_b - learningRate*der_b2\n",
    "    layer1_w = layer1_w - learningRate*der_w1\n",
    "    layer1_b = layer1_b - learningRate*der_b1\n",
    "    #layer1_w.shape\n",
    "    #der_w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Accuracy Stage\n",
    "def evaluateNetworkAccuracy(x,y,w1,b1,w2,b2):\n",
    "    z_1 = np.dot(w1,x)+b1\n",
    "    a_1 = sigmoid(z_1)\n",
    "\n",
    "    z_2 = np.dot(w2,a_1)+b2\n",
    "    a_2 = sigmoid(z_2)\n",
    "\n",
    "    predictions = np.argmax(a_2, axis = 0)\n",
    "    #print(predictions)\n",
    "    \n",
    "    return(np.sum(np.equal(y,predictions))/len(y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98499999999999999"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateNetworkAccuracy(Xdata,labels[0:trainingSize],layer1_w,layer1_b,layer2_w,layer2_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
